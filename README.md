# M4 - ETLT en AWS

---

## Avance I - DiseÃ±o ETLT

- Desarrollo de un documento tÃ©cnico que describa el diseÃ±o del pipeline ETLT.

- Proporciona una descripciÃ³n de la arquitectura, las fuentes de datos utilizadas, detalles del stack tecnolÃ³gico seleccionado, preguntas de negocio, etc. AdemÃ¡s, incluye cuestiones de gobernanza de datos y del ciclo de vida de la informaciÃ³n.

- **Diagrama**
![`architecture-m4`](assets/figs/architecture-m4.png) 
---

## Avance II - Ingesta â†’ Bronze 

- Se resuelve la ingesta automatizada de datos meteorolÃ³gicos desde la API de OpenWeather hacia la capa Bronze del Data Lake. Se utiliza Airbyte tanto para la extracciÃ³n y como para la carga de los datos.

- La ejecuciÃ³n del proceso estÃ¡ programada para realizarse de manera diaria. Dicha ejecuciÃ³n genera archivos que se particionan por fecha y ciudad. 

- Los archivos generados son la base de la siguiente fase la cual tiene como output las capas Silver y Gold.

### GeneraciÃ³n de la capa Bronze.

- La capa Bronze es el primer nivel del Data Lake, donde se almacenan los datos en su formato original, casi sin procesar y casi tal cual como son obtenidos de las fuentes externas. 

- Se tienen dos rutas de ingesta de datos:

    - Ingesta automatizada: los datos provenientes de la API de OpenWeather se extraen de manera programada y automÃ¡tica (Airbyte)
    - Ingesta manual: carga de datos histÃ³ricos vÃ­a archivos JSON
 
### ðŸ“‚ Estructura del bucket en S3



```text
s3://dept01-m4-bronze/
â”œâ”€â”€ api_airbyte/                       # Ingesta automÃ¡tica 
â”‚   â””â”€â”€ openweather/                   
â”‚       â””â”€â”€ <ciudad>/                  # API2.5OWPatagonia/Riohacha
â”‚           â””â”€â”€ year=<YYYY>/           
â”‚               â””â”€â”€ month=<MM>/        
â”‚                   â””â”€â”€ day=<DD>/      
â”‚                       â””â”€â”€ *.parquet  
â””â”€â”€ manual_upload/                     # Ingesta manual
    â””â”€â”€ city-<ciudad>/          
        â””â”€â”€ ingest_date=<YYYY-MM-DD>/  
            â””â”€â”€ *.json                 
```
###  â˜ï¸ OpenWeather â†’ S3 Bronze

- Se usa Airbyte Cloud. Despliegue sencillo y ejecuciÃ³n segÃºn configuraciÃ³n.

#### 1. Source 

**Conector -->** HTTP API (custom)  
**Endpoint -->** `[GET] https://api.openweathermap.org/data/2.5/weather`  
**Retrieval type:** Synchronous Request

**ParÃ¡metros globales**

| Campo | DescripciÃ³n | Valor |
|--------|--------------|-------------------|
| `api_key` | API key de OpenWeather  | `{{ config['api_key'] }}` |
| `Source name` | Nombre del conector | `APIOpenWeather` ||


#### 2. Streams 

En el conector se definen dos streams, uno para cada ciudad.  
Cada stream invoca al endpoint con los parÃ¡metros propios de cada ciudad.  

##### `API2.5OWRiohacha`

- **ParÃ¡metros:**
  | Key | Value |
  |-----|--------|
  | `lat` | `11.538415` |
  | `lon` | `-72.916784` |
  | `lang` | `es` |
  | `units` | `metric` |



##### `API2.5OWPatagonia`

- **ParÃ¡metros:**
  | Key | Value |
  |-----|--------|
  | `lat` | `-41.810147` |
  | `lon` | `-68.906269` |
  | `lang` | `es` |
  | `units` | `metric` |


#### 3. Destination

**Tipo -->** Amazon S3  
**VersiÃ³n -->** v1.9.4  
**Bucket --> ** `dept01-m4-bronze `  
**RegiÃ³n -->** `us-east-1`  
**Ruta base -->** `airbyte/openweather/`  
**Formato de salida -->** `Parquet`
**CompresiÃ³n -->** `SNAPPY` 
**TamaÃ±o de bloque -->** `128 MB`

**Particiones**

| Campo | Valor|
|--------|-------------------|
| `S3 Path Format` | `${STREAM_NAME}/year=${YEAR}/month=${MONTH}/day=${DAY}/` |
| `File Name Pattern` | `{timestamp}_part_{part_number}.parquet` |


#### 4. ConexiÃ³n

| ParÃ¡metro | Valor |
|------------|--------|
| **Connection name** | `APIOpenWeather â†’ S3-M4-dept01` |
| **Schedule type** | CRON |
| **CRON expression** | `0 0 23 * * ?` |
| **Time zone** | `UTC` |
| **Sync mode** | Full Refresh / Append |

- Sobrescribe/agrega segÃºn el modo de escritura, segÃºn especificaciÃ³n de particiones.

![Airbyte conexiÃ³n](assets/figs/avance2-airbyte.png)


### âœï¸ Algunos comentarios
- Variables con valor definido `{{ config[api_key] }}` evitan exponer informaciÃ³n sensible directamente en el cÃ³digo.   
- Se optÃ³ por el formato Parquet con compresiÃ³n Snappy por eficiencia en almacenamiento y la velocidad de lectura (posterior) desde Spark en la capa Silver.
- La extracciÃ³n se ejecuta de manera automÃ¡tica programada por CRON en Airbyte Cloud.

---

## Avance III - Bronze --> Silver/Gold

- En esta etapa del PI se lleva a cabo el procesamiento y modelado de los datos de la capa Bronze en el Data Lake, generando primero la capa intermedia Silver y luego la capa Gold.

- La soluciÃ³n se despliega en la nube de AWS. Los datos se almacenan en Amazon S3, mientras que todo el procesamiento se realiza con Apache Spark ejecutado en contenedores Docker sobre instancias EC2.
    - Infra AWS
         - Amazon S3 (capas bronze/siver/gold).
         - EC2 + Docker (procesamiento con Spark).
         - IAM Role (autenticaciÃ³n segura sin keys para poder acceder a S3).

- Se limpian, normalizan y enriquecen los datos de la capa bronze.
    - [`weather_silver_job.py`](spark-m4/app/weather_silver_job.py) â†’ procesamiento 

- Se generan en la capa Gold, modelos que pretenden responder algunas de las preguntas de negocio planteadas.
    -  [`weather_gold_job.py`](spark-m4/app/weather_gold_job.py) â†’ modelado analÃ­tico (dims, facts, algunas respuestas)

- Flujo 
    ![Diagrama del flujo ETLT](assets/figs/avance3-flujo.png)


## 7. ðŸ—‚ï¸ Estructura del proyecto

```text
â”œâ”€â”€ app/
|    â”œâ”€â”€ wctes/ 
|    |   â”œâ”€â”€ c_silver.py                   # constantes
|    |   â”œâ”€â”€ c_gold.py                     # constantes  
|    â”œâ”€â”€ utils  
|    |   â”œâ”€â”€ u_silver.py                   # fns para job 
|    |   â”œâ”€â”€ u_gold.py                     # fns para job
|    â”œâ”€â”€ weather_silver_job.py             # tf para generar capa silver
|    â”œâ”€â”€ weather_gold_job.py               # tf para generar capa gold
â”‚
â”œâ”€â”€ conf/                                  # config spark
â”‚   â””â”€â”€ spark-defaults.conf                # ParÃ¡metros por defecto para sesiones de Spark
â”‚
â”œâ”€â”€ Dockerfile                             # img base y dependencias
â”œâ”€â”€ docker-compose.yml                     # orquestaciÃ³n
â”œâ”€â”€ upload2ec2.sh                          # script local --> ec2  



```
### âš¡Arriba

```bash
# 1)  Crear la magen
docker compose build

# 2) Levantando el servicio
docker compose up -d

```

### ðŸª£ Estructura de los buckets

```bash
Particionado por city/event_year/event_month/event_day:

s3://dept01-m4-silver/
â””â”€â”€ weather/
    â””â”€â”€ city=<ciudad>/   #Patagonia/Riohacha              
        â””â”€â”€ event_year=YYYY/
            â””â”€â”€ event_month=MM/
                â””â”€â”€ event_day=DD/
                    â””â”€â”€ part-*.snappy.parquet

s3://dept01-m4-gold/
â””â”€â”€ weather/
    â”œâ”€â”€ dim_date/
    â”œâ”€â”€ dim_city/
    â”œâ”€â”€ dim_weather_condition/
    â”œâ”€â”€ fact_weather_hourly/ 
    â”œâ”€â”€ fact_weather_daily/  
    â””â”€â”€ bsq/
        â”œâ”€â”€ solar_hour_by_month/
        â”œâ”€â”€ wind_hour_by_month/
        â”œâ”€â”€ rps_var/
        â”œâ”€â”€ day_vs_last_year_day/date=YYYY-MM-DD/
        â”œâ”€â”€ best_days_top/
        â”œâ”€â”€ worst_days_top/
        â”œâ”€â”€ htemps_top/
        â”œâ”€â”€ ltemps_top/
```

## IMPORTANTE

- Los jobs se ejecutan de manera manual. 


```bash

# historicos (silver)
sudo docker exec -it spark bash -lc '
/opt/bitnami/spark/bin/spark-submit \
  /opt/etlt/app/weather_silver_job.py \
  --mode historical_mode \
  --ingest-date 2025-10-22 \
  --shuffle-partitions 4
'
# diario (silver)
sudo docker exec -it spark bash -lc '
/opt/bitnami/spark/bin/spark-submit \
  /opt/etlt/app/weather_silver_job.py \
  --mode day_mode \
  --date 2025-10-23 \
  --shuffle-partitions 4
'

# gold
sudo docker exec -it spark bash -lc '
/opt/bitnami/spark/bin/spark-submit \
  /opt/etlt/app/weather_gold_job.py \
  --years-keep "2024,2025" \
  --cities "Riohacha,Patagonia" \
  --compare-date 2025-10-10 \
  --shuffle-partitions 8 \
  --max-records-per-file 50000
'
```

### ðŸ“Š VisualizaciÃ³n de algunos resultados

- Potencia solar promedio vs hr 
  ![`ps-vs-hr`](assets/figs/ps-month-mean-vs-hr.png) 

  - Potencia eÃ³lica promedio vs hr 
  ![`pw-vs-hr`](assets/figs/pw-month-mean-vs-hr.png) 

  - Potencia solar promedio vs mes 
  ![`pw-vs-mm`](assets/figs/pw-month-mean-vs-month.png) 

  - VariaciÃ³n porcentual vs referencia
  ![`delta-rps`](assets/figs/rps-vs-month.png) 

  - Temperatura mÃ¡xima y mÃ­nima alcanzadas 
  ![`temp-M/m`](assets/figs/hc-temps-vs-city.png) 

  - Temperatura vs mes 
  ![`temp-vs-mm`](assets/figs/temphandl-vs-month.png) 

  - Top 5 dias calientes y frios
  ![`top5-dc&c`](assets/figs/top5handcdays.png) 

  - Potencia solar promedio vs hr 
  ![`b&wd-rps-dd`](assets/figs/bandwrpsday.png)
